%% Read in Data

% Change filepath to where you placed the csv files
filepath = '/Users/ryannguyen/Desktop/';

rng('shuffle') % Seed random number generator
pos = readtable([filepath,'positive.data.set.csv']); % Read in disruptive SNV data into table
neg = readtable([filepath,'negative.data.set.csv']); % Read in non-disruptive SNV data
k = size(pos,1);
k2 = size(neg,1);

% Take a random sample of the negative data so that we have a balanced data set
neg0 = datasample(neg, k, 'replace', false); 

%% Make composite data table (x) and true classification variable
x = [pos;neg0]; %Both positive and negative data appended to each other in one big friggin dataset
y = cell(size(x,1),1);
y(1:k) = {'pos'};
y((k+1):size(x,1))= {'neg'};

% Set the number of trees to be made in the bagging process
NumTrees=500;

%%### training and sampling data set
N=size(x,1); % Total number of SNV in balanced set
n=floor(N*0.8); % Let our training data be composed of 80% of our data
index_train=randsample(1:N,n,false); % Randomly select indices for training data
index_test=setdiff(1:N,index_train); % The test data will be composed of the rest

%% Assign data to test and train data variables
% x_train=x(index_train,:);
% y_train=y(index_train);
% x_test=x(index_test,:);
% y_test=y(index_test);

%% Use only one column at a time
feature_list = 1:14;
succ_list = zeros(1,14);

for i = 1:14
    x_subset = x{:,i};

    x_train=x_subset(index_train);
    y_train=y(index_train);
    x_test=x_subset(index_test);
    y_test=y(index_test);


    % Use TreeBagger to classify data based on the full set of features

    rf_all = TreeBagger(NumTrees,x_train,y_train,'OOBPrediction','On','Method','classification');
    y_pred_all=predict(rf_all,x_test);

    % Calculate the performance of the classifier
    succ_rate = mean(strcmp(y_test, y_pred_all)); % Use strcmp to compare the predicted to true classification
    %sprintf('Using all features, we successfully classified %1.1f%% of SNVs in the test data', succ_rate*100)
    
    % Store success rate into array
    succ_list(i) = succ_rate ;
    % One Classifer
    sprintf('Using feature %1.1f%% we successfully classified %1.1f%% of SNVs in the test data', i, succ_rate*100)
end

%% Use two highest columns

horzcat(x{:,})

%% Notes on Tables

% You can take a slice of a table the same way 
x_train_slice = x_test(:,[1,5,7,8]);

% You can convert the data from a table to an array/matrix with the
% following function
slice_data = table2array(x_train_slice);

%% Useful functions for decision trees

Error = oobError(rf_all,'Mode','individual'); % Look at the error of each individual tree
ind=10;
view(rf_all.Trees{ind},'Mode','graph') % Plot the tree at index ind